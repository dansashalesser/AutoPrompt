{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): | WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\n",
      "WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.11.0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "datasets-3.1.0       | 325 KB    |                                       |   0% \n",
      "pyarrow-core-18.0.0  | 3.7 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "snappy-1.2.1         | 35 KB     |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "aws-c-sdkutils-0.2.1 | 49 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "orc-2.0.3            | 428 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1.20191231 | 94 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-tzdata-2024.2 | 139 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "re2-2024.07.02       | 26 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.1.7          | 82 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "async-timeout-4.0.3  | 11 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.1.0      | 51 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-0.3.7      | 420 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pycparser-2.22       | 103 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "azure-storage-files- | 191 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 25 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yarl-1.18.0          | 126 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpfr-4.2.1           | 337 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typing-extensions-4. | 10 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.5.0  | 21 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 15 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gitpython-3.1.43     | 153 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-cpu-1.8.0      | 17 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-3.1.0       | 325 KB    | #8                                    |   5% [A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "datasets-3.1.0       | 325 KB    | ################################7     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "orc-2.0.3            | 428 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "datasets-3.1.0       | 325 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "snappy-1.2.1         | 35 KB     | ################9                     |  46% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "aws-c-sdkutils-0.2.1 | 49 KB     | ############                          |  33% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "snappy-1.2.1         | 35 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "aws-c-sdkutils-0.2.1 | 49 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-tzdata-2024.2 | 139 KB    | ####2                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | 1                                     |   0% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1.20191231 | 94 KB     | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "re2-2024.07.02       | 26 KB     | ######################5               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1.20191231 | 94 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "re2-2024.07.02       | 26 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.1.7          | 82 KB     | #######1                              |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.1.7          | 82 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | #7                                    |   5% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-tzdata-2024.2 | 139 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-tzdata-2024.2 | 139 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "async-timeout-4.0.3  | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ####1                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "async-timeout-4.0.3  | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.1.0      | 51 KB     | ###########6                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ####9                                 |  13% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.1.0      | 51 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-0.3.7      | 420 KB    | #4                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ########8                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ########5                             |  23% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pycparser-2.22       | 103 KB    | #####7                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-0.3.7      | 420 KB    | ###################################2  |  95% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ##############                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pycparser-2.22       | 103 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ############3                         |  33% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 25 KB     | ########################              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ###################8                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 25 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ################5                     |  45% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yarl-1.18.0          | 126 KB    | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ########################9             |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yarl-1.18.0          | 126 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ###################9                  |  54% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ##############################1       |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpfr-4.2.1           | 337 KB    | #7                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-0.3.7      | 420 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | #######################9              |  65% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typing-extensions-4. | 10 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typing-extensions-4. | 10 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpfr-4.2.1           | 337 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ##################################9   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 15 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ###########################4          |  74% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 15 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.4.0        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.5.0  | 21 KB     | ############################1         |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.5.0  | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-cpu-1.8.0      | 17 KB     | ##################################4   |  93% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-cpu-1.8.0      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ################################7     |  88% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "azure-storage-files- | 191 KB    | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gitpython-3.1.43     | 153 KB    | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "azure-storage-files- | 191 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gitpython-3.1.43     | 153 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ##################################### | 100% \u001b[A\n",
      "pyarrow-core-18.0.0  | 3.7 MB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Installing pip dependencies: - Ran pip subprocess with arguments:\n",
      "['/Users/ogc2020/anaconda3/envs/AutoPrompt/bin/python', '-m', 'pip', 'install', '-U', '-r', '/Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt', '--exists-action=b']\n",
      "Pip subprocess output:\n",
      "Collecting prodict (from -r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 1))\n",
      "  Downloading prodict-0.8.20.tar.gz (4.7 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting argilla==1.25.0 (from -r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading argilla-1.25.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting schedule (from -r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 3))\n",
      "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pandas in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from -r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 4)) (2.2.3)\n",
      "Collecting easydict (from -r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 5))\n",
      "  Downloading easydict-1.13-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pillow==10.2.0 (from -r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 6))\n",
      "  Downloading pillow-10.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting langchain-google-genai==0.0.9 (from -r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading langchain_google_genai-0.0.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting httpx<=0.26,>=0.15 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting deprecated~=1.2.0 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (2.10.1)\n",
      "Collecting wrapt<1.15,>=1.13 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting numpy<1.24.0 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading numpy-1.23.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (4.67.0)\n",
      "Collecting backoff (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting monotonic (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rich!=13.1.0 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting typer<0.10.0,>=0.6.0 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting nltk<4.0.0 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-generativeai<0.4.0,>=0.3.1 (from langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Using cached google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from pandas->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from pandas->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from pandas->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 4)) (2024.2)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting google-auth (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: protobuf in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (5.28.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: anyio in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from httpx<=0.26,>=0.15->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from httpx<=0.26,>=0.15->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from httpx<=0.26,>=0.15->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from httpx<=0.26,>=0.15->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from httpx<=0.26,>=0.15->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from httpcore==1.*->httpx<=0.26,>=0.15->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (0.1.145)\n",
      "Collecting packaging>=20.0 (from argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (8.5.0)\n",
      "Requirement already satisfied: click in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from nltk<4.0.0->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from nltk<4.0.0->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from nltk<4.0.0->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from pydantic>=1.10.7->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from pydantic>=1.10.7->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 4)) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich!=13.1.0->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich!=13.1.0->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (1.0.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from anyio->httpx<=0.26,>=0.15->argilla==1.25.0->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 2)) (1.2.2)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading grpcio-1.68.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ogc2020/anaconda3/envs/AutoPrompt/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7)) (2.2.3)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r /Users/ogc2020/Documents/GitHub/AutoPrompt/condaenv.3dgmlqwv.requirements.txt (line 7))\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading argilla-1.25.0-py3-none-any.whl (415 kB)\n",
      "Downloading pillow-10.2.0-cp310-cp310-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading langchain_google_genai-0.0.9-py3-none-any.whl (17 kB)\n",
      "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Downloading easydict-1.13-py3-none-any.whl (6.8 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading google_generativeai-0.3.2-py3-none-any.whl (146 kB)\n",
      "Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m598.7/598.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-macosx_11_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Downloading wrapt-1.14.1-cp310-cp310-macosx_11_0_arm64.whl (35 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading grpcio-1.68.0-cp310-cp310-macosx_12_0_universal2.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: prodict\n",
      "  Building wheel for prodict (pyproject.toml): started\n",
      "  Building wheel for prodict (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for prodict: filename=prodict-0.8.20-py3-none-any.whl size=3917 sha256=afd2e3ea5e8e37ecc2a892650ce64d2aa6a177d1a7ffc603403a4e0c6f1b6f0b\n",
      "  Stored in directory: /Users/ogc2020/Library/Caches/pip/wheels/50/30/d5/c833ca991946a1794fb287680f6ce648d0491ac3d9ceb15cc8\n",
      "Successfully built prodict\n",
      "Installing collected packages: monotonic, easydict, wrapt, typer, schedule, pygments, pyasn1, protobuf, prodict, pillow, packaging, numpy, nltk, mdurl, grpcio, cachetools, backoff, rsa, pyasn1-modules, proto-plus, markdown-it-py, httpx, googleapis-common-protos, deprecated, rich, grpcio-status, google-auth, langchain-core, google-api-core, argilla, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.2\n",
      "    Uninstalling protobuf-5.28.2:\n",
      "      Successfully uninstalled protobuf-5.28.2\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.2\n",
      "    Uninstalling httpx-0.27.2:\n",
      "      Successfully uninstalled httpx-0.27.2\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.20\n",
      "    Uninstalling langchain-core-0.3.20:\n",
      "      Successfully uninstalled langchain-core-0.3.20\n",
      "Successfully installed argilla-1.25.0 backoff-2.2.1 cachetools-5.5.0 deprecated-1.2.15 easydict-1.13 google-ai-generativelanguage-0.4.0 google-api-core-2.23.0 google-auth-2.36.0 google-generativeai-0.3.2 googleapis-common-protos-1.66.0 grpcio-1.68.0 grpcio-status-1.62.3 httpx-0.26.0 langchain-core-0.1.53 langchain-google-genai-0.0.9 markdown-it-py-3.0.0 mdurl-0.1.2 monotonic-1.6 nltk-3.9.1 numpy-1.23.5 packaging-23.2 pillow-10.2.0 prodict-0.8.20 proto-plus-1.25.0 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 pygments-2.18.0 rich-13.9.4 rsa-4.9 schedule-1.2.2 typer-0.9.4 wrapt-1.14.1\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate AutoPrompt\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "usage: conda [-h] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'doctor', 'server', 'pack', 'inspect', 'content-trust', 'metapackage', 'convert', 'token', 'render', 'debug', 'index', 'repo', 'verify', 'develop', 'build', 'env', 'skeleton')\n"
     ]
    }
   ],
   "source": [
    "!conda env create -f environment_dev.yml\n",
    "!conda activate AutoPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: argilla==1.25.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: schedule==1.2.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: pandas==1.5.3 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: prodict==0.8.18 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.8.18)\n",
      "Collecting langchain==0.1.9 (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for langchain==0.1.9 from https://files.pythonhosted.org/packages/45/05/2d5c38c7fa1a091a61e018070b6878410d256be577e5154843d339e59b2c/langchain-0.1.9-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.1.9-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai==1.1.0 (from -r requirements.txt (line 7))\n",
      "  Obtaining dependency information for openai==1.1.0 from https://files.pythonhosted.org/packages/77/b4/8de305dd47c13e3ac2e8eef6dc1ebc6f0884d4ac67af9f86d612c949ab63/openai-1.1.0-py3-none-any.whl.metadata\n",
      "  Using cached openai-1.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting tiktoken==0.5.1 (from -r requirements.txt (line 8))\n",
      "  Obtaining dependency information for tiktoken==0.5.1 from https://files.pythonhosted.org/packages/fb/2a/3d02ef030f387c373acbeca6d5a2307405a1da735285ec12a9ed0b6302ea/tiktoken-0.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached tiktoken-0.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: easydict==1.11 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.11)\n",
      "Requirement already satisfied: wandb==0.16.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.16.0)\n",
      "Collecting transformers==4.35.2 (from -r requirements.txt (line 11))\n",
      "  Obtaining dependency information for transformers==4.35.2 from https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (1.3.2)\n",
      "Requirement already satisfied: faiss-cpu==1.7.4 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (1.7.4)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.2.2)\n",
      "Requirement already satisfied: langchain-google-genai==0.0.9 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.0.9)\n",
      "Requirement already satisfied: pillow==10.2.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (10.2.0)\n",
      "Requirement already satisfied: httpx<=0.26,>=0.15 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (0.26.0)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: numpy<1.24.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: backoff in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: monotonic in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (1.6)\n",
      "Requirement already satisfied: rich!=13.1.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (13.7.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.6.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (0.9.4)\n",
      "Requirement already satisfied: nltk<4.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla==1.25.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2022.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (0.0.38)\n",
      "Collecting langchain-core<0.2,>=0.1.26 (from langchain==0.1.9->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for langchain-core<0.2,>=0.1.26 from https://files.pythonhosted.org/packages/6a/10/285fa149ce95300d91ea0bb124eec28889e5ebbcb59434d1fe2f31098d72/langchain_core-0.1.53-py3-none-any.whl.metadata\n",
      "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (0.1.129)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain==0.1.9->-r requirements.txt (line 6)) (8.2.2)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from openai==1.1.0->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from openai==1.1.0->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from openai==1.1.0->-r requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from tiktoken==0.5.1->-r requirements.txt (line 8)) (2022.7.9)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (3.1.43)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (67.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from wandb==0.16.0->-r requirements.txt (line 10)) (4.25.3)\n",
      "Requirement already satisfied: filelock in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from transformers==4.35.2->-r requirements.txt (line 11)) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from transformers==4.35.2->-r requirements.txt (line 11)) (0.21.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from transformers==4.35.2->-r requirements.txt (line 11)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from transformers==4.35.2->-r requirements.txt (line 11)) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 12)) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 12)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 12)) (2.2.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (0.20.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (0.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9->-r requirements.txt (line 6)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9->-r requirements.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9->-r requirements.txt (line 6)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9->-r requirements.txt (line 6)) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9->-r requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai==1.1.0->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai==1.1.0->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.9->-r requirements.txt (line 6)) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.9->-r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb==0.16.0->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.0->-r requirements.txt (line 10)) (4.0.11)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (0.4.0)\n",
      "Requirement already satisfied: google-auth in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (2.28.1)\n",
      "Requirement already satisfied: google-api-core in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (2.17.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (1.23.0)\n",
      "Requirement already satisfied: certifi in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpx<=0.26,>=0.15->argilla==1.25.0->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpx<=0.26,>=0.15->argilla==1.25.0->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<=0.26,>=0.15->argilla==1.25.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 11)) (2023.10.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.9->-r requirements.txt (line 6)) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain==0.1.9->-r requirements.txt (line 6)) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10.7->argilla==1.25.0->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10.7->argilla==1.25.0->-r requirements.txt (line 1)) (2.14.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.9->-r requirements.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from rich!=13.1.0->argilla==1.25.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from rich!=13.1.0->argilla==1.25.0->-r requirements.txt (line 1)) (2.15.1)\n",
      "Requirement already satisfied: networkx in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (1.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.0->-r requirements.txt (line 10)) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla==1.25.0->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.9->-r requirements.txt (line 6)) (0.4.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (1.62.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (4.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (2.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (1.62.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (1.62.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9->-r requirements.txt (line 15)) (0.4.8)\n",
      "Using cached langchain-0.1.9-py3-none-any.whl (816 kB)\n",
      "Using cached openai-1.1.0-py3-none-any.whl (217 kB)\n",
      "Using cached tiktoken-0.5.1-cp311-cp311-macosx_11_0_arm64.whl (924 kB)\n",
      "Using cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "Using cached langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Installing collected packages: tiktoken, openai, transformers, langchain-core, langchain\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.8.0\n",
      "    Uninstalling tiktoken-0.8.0:\n",
      "      Successfully uninstalled tiktoken-0.8.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.54.4\n",
      "    Uninstalling openai-1.54.4:\n",
      "      Successfully uninstalled openai-1.54.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.1\n",
      "    Uninstalling transformers-4.32.1:\n",
      "      Successfully uninstalled transformers-4.32.1\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.19\n",
      "    Uninstalling langchain-core-0.3.19:\n",
      "      Successfully uninstalled langchain-core-0.3.19\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.7\n",
      "    Uninstalling langchain-0.3.7:\n",
      "      Successfully uninstalled langchain-0.3.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-benchmarks 0.0.14 requires langchain<0.3.0,>=0.2.7, but you have langchain 0.1.9 which is incompatible.\n",
      "langchain-benchmarks 0.0.14 requires langchain-community<0.3,>=0.2, but you have langchain-community 0.0.38 which is incompatible.\n",
      "langchain-benchmarks 0.0.14 requires langchain-openai<0.2.0,>=0.1.14, but you have langchain-openai 0.2.9 which is incompatible.\n",
      "langchain-openai 0.2.9 requires langchain-core<0.4.0,>=0.3.17, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-openai 0.2.9 requires openai<2.0.0,>=1.54.0, but you have openai 1.1.0 which is incompatible.\n",
      "langchain-openai 0.2.9 requires tiktoken<1,>=0.7, but you have tiktoken 0.5.1 which is incompatible.\n",
      "langchain-text-splitters 0.3.2 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.1.9 langchain-core-0.1.53 openai-1.1.0 tiktoken-0.5.1 transformers-4.35.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Anotator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: argilla in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (1.25.0)\n",
      "Requirement already satisfied: httpx<=0.26,>=0.15 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (0.26.0)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (1.2.14)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (23.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (1.5.3)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (2.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (1.14.1)\n",
      "Requirement already satisfied: numpy<1.24.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (4.66.1)\n",
      "Requirement already satisfied: backoff in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (2.2.1)\n",
      "Requirement already satisfied: monotonic in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (1.6)\n",
      "Requirement already satisfied: rich!=13.1.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (13.7.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.6.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (0.9.4)\n",
      "Requirement already satisfied: nltk<4.0.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from argilla) (3.7)\n",
      "Requirement already satisfied: anyio in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpx<=0.26,>=0.15->argilla) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpx<=0.26,>=0.15->argilla) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpx<=0.26,>=0.15->argilla) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpx<=0.26,>=0.15->argilla) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpx<=0.26,>=0.15->argilla) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<=0.26,>=0.15->argilla) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0->argilla) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0->argilla) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0->argilla) (2022.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.0->argilla) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.0->argilla) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10.7->argilla) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10.7->argilla) (2.14.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10.7->argilla) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from rich!=13.1.0->argilla) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from rich!=13.1.0->argilla) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ogc2020/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->argilla) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install argilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Bias setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "## copy this into the terminal\n",
    "# !pip install wandb\n",
    "# !wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdansashadan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ogc2020/Documents/GitHub/AutoPrompt/wandb/run-20241123_161407-680zpf9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dansashadan/my-awesome-project/runs/680zpf9r' target=\"_blank\">major-galaxy-1</a></strong> to <a href='https://wandb.ai/dansashadan/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dansashadan/my-awesome-project' target=\"_blank\">https://wandb.ai/dansashadan/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dansashadan/my-awesome-project/runs/680zpf9r' target=\"_blank\">https://wandb.ai/dansashadan/my-awesome-project/runs/680zpf9r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8c6fe5fc294d51bc31b55d80d2ff3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.030 MB uploaded\\r'), FloatProgress(value=0.030437799646732273, max=1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.74977</td></tr><tr><td>loss</td><td>0.24823</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-galaxy-1</strong> at: <a href='https://wandb.ai/dansashadan/my-awesome-project/runs/680zpf9r' target=\"_blank\">https://wandb.ai/dansashadan/my-awesome-project/runs/680zpf9r</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241123_161407-680zpf9r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimization_pipeline import OptimizationPipeline\n",
    "from utils.config import load_yaml, override_config\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g9kzqm66) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a54748cb084aefbe3eb022d7f892dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.174 MB of 0.174 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Total usage</td><td></td></tr><tr><td>score</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Total usage</td><td>0.32537</td></tr><tr><td>score</td><td>0.76</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-shape-1</strong> at: <a href='https://wandb.ai/dansashadan/AutoGPT/runs/g9kzqm66' target=\"_blank\">https://wandb.ai/dansashadan/AutoGPT/runs/g9kzqm66</a><br/>Synced 6 W&B file(s), 51 media file(s), 34 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241124_140332-g9kzqm66/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:g9kzqm66). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ogc2020/Documents/GitHub/AutoPrompt/wandb/run-20241124_141223-d9evxazc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dansashadan/AutoGPT/runs/d9evxazc' target=\"_blank\">leafy-yogurt-2</a></strong> to <a href='https://wandb.ai/dansashadan/AutoGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dansashadan/AutoGPT' target=\"_blank\">https://wandb.ai/dansashadan/AutoGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dansashadan/AutoGPT/runs/d9evxazc' target=\"_blank\">https://wandb.ai/dansashadan/AutoGPT/runs/d9evxazc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting step 0\n",
      "Dataset is empty generating initial samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 1/1 [00:21<00:00, 21.63s/it]\n",
      "Processing samples: 100%|| 10/10 [00:01<00:00,  5.40it/s]\n",
      "Processing samples: 100%|| 10/10 [00:19<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.0\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Hiring Plan Generator Classification Task\n",
      "\n",
      "Classify whether the provided hiring plan is suitable for a company in a specific sector, taking into consideration the following constraints:\n",
      "\n",
      "- The plan must be tailored to the unique roles pertinent to the sector (e.g., agricultural tech, blockchain technology, space exploration, cybersecurity).\n",
      "- The budget outlined in the plan must not exceed the company's yearly balance.\n",
      "- The plan must respect any start date restrictions, with hires being made after the specified date.\n",
      "- There must be a diversity of roles within departments rather than multiples of the same role, unless explicitly requested.\n",
      "- Compliance roles and Financial Analysts must not be included in the hiring plan.\n",
      "- The plan should prioritize top management roles based on the sector and address all requirements mentioned in the provided Freetext.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan meets all the specified constraints and is suitable for the company within its sector.\n",
      "- No: The hiring plan does not meet one or more of the specified constraints and is not suitable for the company within its sector.\n",
      "\n",
      "**Note:** Do not return an empty response or fail to classify according to the constraints, as this will result in an incorrect classification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 1/1 [00:14<00:00, 14.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 10/10 [00:01<00:00,  7.13it/s]\n",
      "Processing samples: 100%|| 20/20 [00:02<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.65\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "Hiring Plan Compliance Checker\n",
      "\n",
      "Determine whether the provided hiring plan meets the necessary criteria for a company in the designated sector. Ensure the hiring plan adheres to the financial limits, sector-specific role requirements, start date mandates, and departmental role diversity as outlined below. Do not include any Compliance roles or Financial Analysts, and confirm top management positions are prioritized.\n",
      "\n",
      "**Criteria for Compliance:**\n",
      "- The total yearly cost of the hiring plan does not exceed the company's stated yearly balance.\n",
      "- The roles are specific to the sector and exhibit necessary variety within departments.\n",
      "- All hires are scheduled to start on or after the specified date in the plan.\n",
      "- The hiring plan is free of Compliance roles and Financial Analysts, which are not to be included.\n",
      "- Top management roles are adequately represented and prioritized.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan is compliant with all the criteria.\n",
      "- No: The hiring plan fails to meet one or more of the criteria.\n",
      "\n",
      "Classify the hiring plan accordingly and be vigilant in scrutinizing each criterion to avoid false positives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 1/1 [00:11<00:00, 11.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 10/10 [00:01<00:00,  7.48it/s]\n",
      "Processing samples: 100%|| 30/30 [00:03<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.5\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Hiring Plan Financial and Management Evaluation Task\n",
      "\n",
      "Evaluate if the hiring plan adheres to the company's financial constraints and properly prioritizes top management roles within the context of the company's sector. Incorporate specific salary information to ensure the total yearly cost does not exceed the company's stated yearly balance. Confirm that top management roles are not only included but are prioritized appropriately in the hiring sequence.\n",
      "\n",
      "**Evaluation Criteria:**\n",
      "- The hiring plan's total yearly cost, including specific salaries, remains within the company's declared yearly balance.\n",
      "- Top management roles are clearly prioritized in the hiring order and adequately represented, according to the sector's needs.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan fulfills both the financial constraint adherence and the prioritization of top management roles.\n",
      "- No: The hiring plan fails to meet the financial constraints or does not properly prioritize top management roles.\n",
      "\n",
      "Evaluate the provided hiring plan against these criteria and classify it accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 1/1 [00:14<00:00, 14.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 10/10 [00:01<00:00,  7.89it/s]\n",
      "Processing samples: 100%|| 40/40 [00:04<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.95\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Sector-Specific Hiring Plan Evaluation Task\n",
      "\n",
      "Evaluate the provided hiring plan to determine if it strategically prioritizes sector-specific top management roles while adhering to the company's financial constraints, including salaries that are realistic within the sector. Ensure the evaluation takes into account the importance of the balance between the cost of top talent and the overall budget.\n",
      "\n",
      "**Evaluation Criteria:**\n",
      "- The hiring plan must include and prioritize top management roles that are essential for the specific sector of the company.\n",
      "- The total yearly cost of the hiring plan, with particular attention to the salary scales within the sector, should not exceed the company's yearly financial balance.\n",
      "- The plan should reflect a realistic approach to hiring top talent within the sector without compromising the financial integrity of the company.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan meets the sector-specific needs for top management roles and respects the financial constraints.\n",
      "- No: The hiring plan fails to prioritize sector-specific top management roles adequately or exceeds the financial constraints.\n",
      "\n",
      "Classify the hiring plan accordingly, ensuring a balanced evaluation of management prioritization and financial feasibility within the sector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 1/1 [00:13<00:00, 13.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|| 10/10 [00:01<00:00,  6.95it/s]\n",
      "Processing samples: 100%|| 50/50 [00:05<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.64\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Sector-Specific Hiring Plan and Financial Assessment Task\n",
      "\n",
      "Evaluate and classify the provided hiring plan based on its alignment with both sector-specific management role prioritization and strict adherence to the company's financial constraints. Ensure that the assessment accurately reflects the company's ability to finance top management roles without exceeding the budget and that sector-specific management roles are appropriately emphasized.\n",
      "\n",
      "**Classification Criteria:**\n",
      "- The hiring plan must not surpass the company's yearly financial limit, taking into account accurate salary figures for each role within the sector.\n",
      "- Sector-specific top management roles should be clearly identified, included, and given priority in the hiring process.\n",
      "- The plan must demonstrate a strategic balance between the financing of essential management roles and the overall budgetary constraints.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan successfully prioritizes sector-specific management roles and maintains the company's financial boundaries.\n",
      "- No: The hiring plan fails to appropriately prioritize sector-specific management roles or violates the company's financial limits.\n",
      "\n",
      "Classify the hiring plan according to these criteria, ensuring a precise and correct evaluation.\n",
      "Starting step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 0it [00:00, ?it/s]\n",
      "Processing samples: 100%|| 50/50 [00:05<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.72\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Hiring Plan Sector-Specific Roles and Budget Adherence Task\n",
      "\n",
      "Evaluate and classify a hiring plan by checking its alignment with the company's financial constraints and its focus on sector-specific top management roles. The hiring plan should neither exceed the company's financial limits nor neglect the prioritization and appropriate compensation of sector-specific top roles.\n",
      "\n",
      "**Evaluation Criteria:**\n",
      "- The hiring plan must prioritize sector-specific top management roles, taking into account competitive salaries that are realistic and in line with industry standards.\n",
      "- The total cost of the hiring plan must fit within the company's financial constraints without compromising the ability to attract top talent in these roles.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan adequately prioritizes sector-specific management roles and stays within financial limits.\n",
      "- No: The hiring plan either overlooks the importance of sector-specific management roles or breaches financial constraints.\n",
      "\n",
      "Classify the hiring plan accordingly to ensure it meets the criteria of prioritizing essential roles and adhering to the budget.\n",
      "Starting step 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 0it [00:00, ?it/s]\n",
      "Processing samples: 100%|| 50/50 [00:05<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.52\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Rigorous Hiring Plan Financial and Sector-Specific Role Analysis Task\n",
      "\n",
      "Classify the hiring plan according to its ability to prioritize essential sector-specific management roles without compromising the predefined financial constraints of the company. The plan should include competitive salary offers for these key roles while remaining within the financial budget. Each role's salary should be evaluated against industry standards, and the total cost should not exceed the company's budgetary limits. The classification should be sensitive to any oversights in both financial calculations and the proper prioritization of sector-specific roles.\n",
      "\n",
      "**Classification Criteria:**\n",
      "- The hiring plan must specifically address and prioritize sector-specific top management roles with competitive yet financially feasible salaries.\n",
      "- The total cost of the hiring plan, including all salaries, must not surpass the company's financial budget.\n",
      "- The evaluation process must accurately identify instances where the hiring plan does not align with financial constraints or sector-specific role prioritization.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan successfully prioritizes sector-specific management roles and respects the company's budgetary boundaries.\n",
      "- No: The hiring plan either does not prioritize the necessary sector-specific roles or fails to adhere to the financial budget.\n",
      "Starting step 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 0it [00:00, ?it/s]\n",
      "Processing samples: 100%|| 50/50 [00:07<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.72\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Balanced Hiring Plan Classification Task\n",
      "\n",
      "Classify the hiring plan by assessing whether it meets the sector-specific needs for top management roles and fits within the financial framework of the company. Take into account both the adherence to the budget and the correct prioritization of sector-specific roles, ensuring that neither is neglected.\n",
      "\n",
      "**Evaluation Criteria:**\n",
      "- Verify that the hiring plan provides competitive salaries for sector-specific top management roles without exceeding the company's financial boundaries.\n",
      "- Confirm that sector-specific management roles are not only included but are also given the right level of priority within the hiring plan.\n",
      "- Evaluate the total cost of the hiring plan, ensuring it does not surpass the financial limit set by the company.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan aligns with the financial and sector-specific requirements.\n",
      "- No: The hiring plan fails to align with either financial constraints or sector-specific role prioritization.\n",
      "Starting step 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 0it [00:00, ?it/s]\n",
      "Processing samples: 100%|| 50/50 [00:05<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous prompt score:\n",
      "0.44\n",
      "#########\n",
      "\n",
      "Get new prompt:\n",
      "# Balanced Hiring Plan Analysis Task\n",
      "\n",
      "Determine whether the hiring plan presents a well-balanced approach to hiring sector-specific top management roles without exceeding the company's financial limits. Assess whether the plan takes into account realistic sector-specific salary ranges, prioritizes the hiring order of top management roles according to the sector's needs, and ensures the total cost is within the financial budget. Correct any model biases towards negative classification, and accurately identify plans that effectively balance top talent acquisition and budgetary constraints.\n",
      "\n",
      "**Evaluation Criteria:**\n",
      "- The hiring plan's adherence to the company's financial budget, considering the sector-specific salary scales for top management positions.\n",
      "- Effective prioritization of sector-specific top management roles in the hiring plan.\n",
      "- A clear balance between the hiring of indispensable management talent and the overall financial limitations of the company.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan achieves a balanced approach to sector-specific management role prioritization within the company's financial limits.\n",
      "- No: The hiring plan does not adequately balance the prioritization of sector-specific management roles or fails to stay within financial boundaries.\n",
      "\n",
      "Classify the hiring plan as 'Yes' or 'No' based on these evaluation criteria.\n",
      "Starting step 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 0it [00:00, ?it/s]\n",
      "Processing samples: 100%|| 50/50 [00:05<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mCalibrated prompt score: 0.95\u001b[0m\n",
      "\u001b[92mCalibrated prompt: # Hiring Plan Financial and Management Evaluation Task\n",
      "\n",
      "Evaluate if the hiring plan adheres to the company's financial constraints and properly prioritizes top management roles within the context of the company's sector. Incorporate specific salary information to ensure the total yearly cost does not exceed the company's stated yearly balance. Confirm that top management roles are not only included but are prioritized appropriately in the hiring sequence.\n",
      "\n",
      "**Evaluation Criteria:**\n",
      "- The hiring plan's total yearly cost, including specific salaries, remains within the company's declared yearly balance.\n",
      "- Top management roles are clearly prioritized in the hiring order and adequately represented, according to the sector's needs.\n",
      "\n",
      "**Classification Labels:**\n",
      "- Yes: The hiring plan fulfills both the financial constraint adherence and the prioritization of top management roles.\n",
      "- No: The hiring plan fails to meet the financial constraints or does not properly prioritize top management roles.\n",
      "\n",
      "Evaluate the provided hiring plan against these criteria and classify it accordingly.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# General Training Parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--basic_config_path', default='config/config_default.yml', type=str, help='Configuration file path')\n",
    "parser.add_argument('--batch_config_path', default='',\n",
    "                    type=str, help='Batch classification configuration file path')\n",
    "parser.add_argument('--prompt',\n",
    "                    default='',\n",
    "                    required=False, type=str, help='Prompt to use as initial.')\n",
    "parser.add_argument('--task_description',\n",
    "                    default='',\n",
    "                    required=False, type=str, help='Describing the task')\n",
    "parser.add_argument('--load_path', default='', required=False, type=str, help='In case of loading from checkpoint')\n",
    "parser.add_argument('--output_dump', default='dump', required=False, type=str, help='Output to save checkpoints')\n",
    "parser.add_argument('--num_steps', default=10, type=int, help='Number of iterations')\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "\n",
    "if opt.batch_config_path == '':\n",
    "    # load the basic configuration using load_yaml\n",
    "    config_params = load_yaml(opt.basic_config_path)\n",
    "else:\n",
    "    # override the basic configuration with the batch configuration\n",
    "    config_params = override_config(opt.batch_config_path, config_file=opt.basic_config_path)\n",
    "\n",
    "if opt.task_description == '':\n",
    "    task_description = input(\"Describe the task: \")\n",
    "else:\n",
    "    task_description = opt.task_description\n",
    "\n",
    "if opt.prompt == '':\n",
    "    initial_prompt = input(\"Initial prompt: \")\n",
    "else:\n",
    "    initial_prompt = opt.prompt\n",
    "\n",
    "# Initializing the pipeline\n",
    "pipeline = OptimizationPipeline(config_params, task_description, initial_prompt, output_path=opt.output_dump)\n",
    "if (opt.load_path != ''):\n",
    "    pipeline.load_state(opt.load_path)\n",
    "best_prompt = pipeline.run_pipeline(opt.num_steps)\n",
    "print('\\033[92m' + 'Calibrated prompt score:', str(best_prompt['score']) + '\\033[0m')\n",
    "print('\\033[92m' + 'Calibrated prompt:', best_prompt['prompt'] + '\\033[0m')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdansashadan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ogc2020/Documents/GitHub/AutoPrompt/wandb/run-20241125_151635-4rm9yl3m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dansashadan/AutoGPT/runs/4rm9yl3m' target=\"_blank\">rich-serenity-9</a></strong> to <a href='https://wandb.ai/dansashadan/AutoGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dansashadan/AutoGPT' target=\"_blank\">https://wandb.ai/dansashadan/AutoGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dansashadan/AutoGPT/runs/4rm9yl3m' target=\"_blank\">https://wandb.ai/dansashadan/AutoGPT/runs/4rm9yl3m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ogc2020/Documents/GitHub/AutoPrompt/utils/llm_chain.py:162: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
      "/Users/ogc2020/Documents/GitHub/AutoPrompt/utils/config.py:125: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  task_result = task_llm_chain(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">47</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>ranker_pipeline.predictor.init_chain(ranker_config_params.dataset.label_schema)         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (ranker_pipeline.cur_prompt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> (ranker_pipeline.task_description <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>47 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>ranker_mod_prompt, ranker_mod_task_desc = modify_input_for_ranker(                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>ranker_config_params, task_description, initial_prompt)                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>ranker_pipeline.cur_prompt = ranker_mod_prompt                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>ranker_pipeline.task_description = ranker_mod_task_desc                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/Documents/GitHub/AutoPrompt/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">config.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">125</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">modify_input_for_ranker</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>llm = get_llm(config.llm)                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>task_llm_chain = LLMChain(llm=llm, prompt=task_desc_setup)                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>125 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>task_result = task_llm_chain(                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>{<span style=\"color: #808000; text-decoration-color: #808000\">\"task_description\"</span>: task_description})                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>mod_task_desc = task_result[<span style=\"color: #808000; text-decoration-color: #808000\">'text'</span>]                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>logging.info(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Task description modified for ranking to: \\n{</span>mod_task_desc<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/_api/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">deprecation.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">182</span> in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">warning_emitting_wrapper</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> warned <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_caller_internal():                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>warned = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>emit_warning()                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>182 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapped(*args, **kwargs)                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">183 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">184 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">async</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">awarning_emitting_wrapper</span>(*args: Any, **kwargs: Any) -&gt; Any:             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">185 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">         </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Same as warning_emitting_wrapper, but for async functions.\"\"\"</span>               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">389</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">386 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #808000; text-decoration-color: #808000\">\"run_name\"</span>: run_name,                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">387 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>}                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">388 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>389 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.invoke(                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">390 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>inputs,                                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">391 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>cast(RunnableConfig, {k: v <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config.items() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>}),      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">392 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>return_only_outputs=return_only_outputs,                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">170</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">invoke</span>     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">BaseException</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>run_manager.on_chain_error(e)                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>170 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> e                                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>run_manager.on_chain_end(outputs)                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> include_run_info:                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">160</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">invoke</span>     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._validate_inputs(inputs)                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>outputs = (                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>160 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call(inputs, run_manager=run_manager)                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> new_arg_supported                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call(inputs)                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">llm.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">126</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call</span>       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>inputs: Dict[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, Any],                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>run_manager: Optional[CallbackManagerForChainRun] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>) -&gt; Dict[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>]:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>126 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>response = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.generate([inputs], run_manager=run_manager)                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.create_outputs(response)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>(                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">llm.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">138</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>prompts, stop = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prep_prompts(input_list, run_manager=run_manager)             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>callbacks = run_manager.get_child() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> run_manager <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.llm, BaseLanguageModel):                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>138 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.llm.generate_prompt(                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>prompts,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>stop,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>callbacks=callbacks,                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chat_models</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">786</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate_prompt</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 783 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>**kwargs: Any,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 784 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>) -&gt; LLMResult:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 785 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>prompt_messages = [p.to_messages() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> p <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> prompts]                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 786 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 787 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 788 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">async</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">agenerate_prompt</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 789 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chat_models</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">643</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">BaseException</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 641 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> run_managers:                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 643 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> e                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>flattened_outputs = [                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 645 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>LLMResult(generations=[res.generations], llm_output=res.llm_output)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type:</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> res <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> results                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chat_models</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, m <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(messages):                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>results.append(                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._generate_with_cache(                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>m,                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>stop=stop,                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>run_manager=run_managers[i] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> run_managers <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chat_models</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">851</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_generate_with_cache</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 848 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>result = generate_from_stream(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">iter</span>(chunks))                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 849 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 850 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> inspect.signature(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._generate).parameters.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"run_manager\"</span>):           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 851 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._generate(                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 852 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>messages, stop=stop, run_manager=run_manager, **kwargs                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 853 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 854 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">689</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_generate</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 686 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>response = raw_response.parse()                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 687 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>generation_info = {<span style=\"color: #808000; text-decoration-color: #808000\">\"headers\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>(raw_response.headers)}                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 688 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 689 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>response = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.client.create(**payload)                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 690 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._create_chat_result(response, generation_info)                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 691 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 692 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_request_payload</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">275</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">f\"Missing required argument: {</span>quote(missing[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">274 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(msg)                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>275 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/resources/chat/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">completions.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">829</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">create</span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 826 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>timeout: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">float</span> | httpx.Timeout | <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> | NotGiven = NOT_GIVEN,                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 827 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>) -&gt; ChatCompletion | Stream[ChatCompletionChunk]:                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 828 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>validate_response_format(response_format)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 829 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._post(                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 830 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #808000; text-decoration-color: #808000\">\"/chat/completions\"</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 831 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>body=maybe_transform(                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 832 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>{                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_base_client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1278</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">post</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1275 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>opts = FinalRequestOptions.construct(                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>method=<span style=\"color: #808000; text-decoration-color: #808000\">\"post\"</span>, url=path, json_data=body, files=to_httpx_files(files), **opti  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1278 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(ResponseT, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.request(cast_to, opts, stream=stream, stream_cls=str  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1279 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1280 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">patch</span>(                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1281 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_base_client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">955</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">request</span>      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 952 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 953 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>retries_taken = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 954 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 955 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._request(                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 956 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>cast_to=cast_to,                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 957 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>options=options,                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 958 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>stream=stream,                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_base_client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1059</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_request</span>    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>err.response.read()                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1057 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1058 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>log.debug(<span style=\"color: #808000; text-decoration-color: #808000\">\"Re-raising status error\"</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1059 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._make_status_error_from_response(err.response) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1060 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1061 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._process_response(                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1062 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>cast_to=cast_to,                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AuthenticationError: </span>Error code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span> - <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'error'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Incorrect API key provided: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sk-WsU5p***************************************qxp9. You can find your API key at </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://platform.openai.com/account/api-keys.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'invalid_request_error'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'param'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'code'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'invalid_api_key'</span><span style=\"font-weight: bold\">}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m47\u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m   \u001b[0mranker_pipeline.predictor.init_chain(ranker_config_params.dataset.label_schema)         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m45 \u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m46 \u001b[0m\u001b[94mif\u001b[0m (ranker_pipeline.cur_prompt \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m) \u001b[95mor\u001b[0m (ranker_pipeline.task_description \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m):      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m47 \u001b[2m   \u001b[0mranker_mod_prompt, ranker_mod_task_desc = modify_input_for_ranker(                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m      \u001b[0mranker_config_params, task_description, initial_prompt)                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m   \u001b[0mranker_pipeline.cur_prompt = ranker_mod_prompt                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m   \u001b[0mranker_pipeline.task_description = ranker_mod_task_desc                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/Documents/GitHub/AutoPrompt/utils/\u001b[0m\u001b[1;33mconfig.py\u001b[0m:\u001b[94m125\u001b[0m in \u001b[92mmodify_input_for_ranker\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m   \u001b[0mllm = get_llm(config.llm)                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m   \u001b[0mtask_llm_chain = LLMChain(llm=llm, prompt=task_desc_setup)                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m125 \u001b[2m   \u001b[0mtask_result = task_llm_chain(                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m      \u001b[0m{\u001b[33m\"\u001b[0m\u001b[33mtask_description\u001b[0m\u001b[33m\"\u001b[0m: task_description})                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m   \u001b[0mmod_task_desc = task_result[\u001b[33m'\u001b[0m\u001b[33mtext\u001b[0m\u001b[33m'\u001b[0m]                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m   \u001b[0mlogging.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mTask description modified for ranking to: \u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m{\u001b[0mmod_task_desc\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/_api/\u001b[0m\u001b[1;33mdeprecation.py\u001b[0m:\u001b[94m182\u001b[0m in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mwarning_emitting_wrapper\u001b[0m                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m warned \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m is_caller_internal():                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m            \u001b[0mwarned = \u001b[94mTrue\u001b[0m                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m181 \u001b[0m\u001b[2m            \u001b[0memit_warning()                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m182 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m wrapped(*args, **kwargs)                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m183 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m184 \u001b[0m\u001b[2m      \u001b[0m\u001b[94masync\u001b[0m \u001b[94mdef\u001b[0m \u001b[92mawarning_emitting_wrapper\u001b[0m(*args: Any, **kwargs: Any) -> Any:             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m185 \u001b[0m\u001b[2;90m         \u001b[0m\u001b[33m\"\"\"Same as warning_emitting_wrapper, but for async functions.\"\"\"\u001b[0m               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m389\u001b[0m in \u001b[92m__call__\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m386 \u001b[0m\u001b[2m         \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mrun_name\u001b[0m\u001b[33m\"\u001b[0m: run_name,                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m387 \u001b[0m\u001b[2m      \u001b[0m}                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m388 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m389 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.invoke(                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m390 \u001b[0m\u001b[2m         \u001b[0minputs,                                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m391 \u001b[0m\u001b[2m         \u001b[0mcast(RunnableConfig, {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m config.items() \u001b[94mif\u001b[0m v \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m}),      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m392 \u001b[0m\u001b[2m         \u001b[0mreturn_only_outputs=return_only_outputs,                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m170\u001b[0m in \u001b[92minvoke\u001b[0m     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m         \u001b[0m)                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mBaseException\u001b[0m \u001b[94mas\u001b[0m e:                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m         \u001b[0mrun_manager.on_chain_error(e)                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m170 \u001b[2m         \u001b[0m\u001b[94mraise\u001b[0m e                                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m      \u001b[0mrun_manager.on_chain_end(outputs)                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m include_run_info:                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m160\u001b[0m in \u001b[92minvoke\u001b[0m     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m._validate_inputs(inputs)                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m         \u001b[0moutputs = (                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m160 \u001b[2m            \u001b[0m\u001b[96mself\u001b[0m._call(inputs, run_manager=run_manager)                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mif\u001b[0m new_arg_supported                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m            \u001b[0m\u001b[94melse\u001b[0m \u001b[96mself\u001b[0m._call(inputs)                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m         \u001b[0m)                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/\u001b[0m\u001b[1;33mllm.py\u001b[0m:\u001b[94m126\u001b[0m in \u001b[92m_call\u001b[0m       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m      \u001b[0minputs: Dict[\u001b[96mstr\u001b[0m, Any],                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m      \u001b[0mrun_manager: Optional[CallbackManagerForChainRun] = \u001b[94mNone\u001b[0m,                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m   \u001b[0m) -> Dict[\u001b[96mstr\u001b[0m, \u001b[96mstr\u001b[0m]:                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m126 \u001b[2m      \u001b[0mresponse = \u001b[96mself\u001b[0m.generate([inputs], run_manager=run_manager)                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.create_outputs(response)[\u001b[94m0\u001b[0m]                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mgenerate\u001b[0m(                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain/chains/\u001b[0m\u001b[1;33mllm.py\u001b[0m:\u001b[94m138\u001b[0m in \u001b[92mgenerate\u001b[0m    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m      \u001b[0mprompts, stop = \u001b[96mself\u001b[0m.prep_prompts(input_list, run_manager=run_manager)             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m      \u001b[0mcallbacks = run_manager.get_child() \u001b[94mif\u001b[0m run_manager \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(\u001b[96mself\u001b[0m.llm, BaseLanguageModel):                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m138 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.llm.generate_prompt(                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m            \u001b[0mprompts,                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m            \u001b[0mstop,                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m            \u001b[0mcallbacks=callbacks,                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/\u001b[0m\u001b[1;33mchat_models\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m786\u001b[0m in \u001b[92mgenerate_prompt\u001b[0m                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 783 \u001b[0m\u001b[2m      \u001b[0m**kwargs: Any,                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 784 \u001b[0m\u001b[2m   \u001b[0m) -> LLMResult:                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 785 \u001b[0m\u001b[2m      \u001b[0mprompt_messages = [p.to_messages() \u001b[94mfor\u001b[0m p \u001b[95min\u001b[0m prompts]                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 786 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 787 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 788 \u001b[0m\u001b[2m   \u001b[0m\u001b[94masync\u001b[0m \u001b[94mdef\u001b[0m \u001b[92magenerate_prompt\u001b[0m(                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 789 \u001b[0m\u001b[2m      \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/\u001b[0m\u001b[1;33mchat_models\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m643\u001b[0m in \u001b[92mgenerate\u001b[0m                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mBaseException\u001b[0m \u001b[94mas\u001b[0m e:                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 641 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mif\u001b[0m run_managers:                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m               \u001b[0mrun_managers[i].on_llm_error(e, response=LLMResult(generations=[]))   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 643 \u001b[2m            \u001b[0m\u001b[94mraise\u001b[0m e                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m      \u001b[0mflattened_outputs = [                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 645 \u001b[0m\u001b[2m         \u001b[0mLLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[2m# type:\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 646 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mfor\u001b[0m res \u001b[95min\u001b[0m results                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/\u001b[0m\u001b[1;33mchat_models\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m633\u001b[0m in \u001b[92mgenerate\u001b[0m                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 630 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m i, m \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(messages):                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 632 \u001b[0m\u001b[2m            \u001b[0mresults.append(                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 633 \u001b[2m               \u001b[0m\u001b[96mself\u001b[0m._generate_with_cache(                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 634 \u001b[0m\u001b[2m                  \u001b[0mm,                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 635 \u001b[0m\u001b[2m                  \u001b[0mstop=stop,                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 636 \u001b[0m\u001b[2m                  \u001b[0mrun_manager=run_managers[i] \u001b[94mif\u001b[0m run_managers \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m,            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/\u001b[0m\u001b[1;33mchat_models\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m851\u001b[0m in \u001b[92m_generate_with_cache\u001b[0m                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 848 \u001b[0m\u001b[2m         \u001b[0mresult = generate_from_stream(\u001b[96miter\u001b[0m(chunks))                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 849 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 850 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m inspect.signature(\u001b[96mself\u001b[0m._generate).parameters.get(\u001b[33m\"\u001b[0m\u001b[33mrun_manager\u001b[0m\u001b[33m\"\u001b[0m):           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 851 \u001b[2m            \u001b[0mresult = \u001b[96mself\u001b[0m._generate(                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 852 \u001b[0m\u001b[2m               \u001b[0mmessages, stop=stop, run_manager=run_manager, **kwargs                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 853 \u001b[0m\u001b[2m            \u001b[0m)                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 854 \u001b[0m\u001b[2m         \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m689\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m_generate\u001b[0m                                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 686 \u001b[0m\u001b[2m         \u001b[0mresponse = raw_response.parse()                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 687 \u001b[0m\u001b[2m         \u001b[0mgeneration_info = {\u001b[33m\"\u001b[0m\u001b[33mheaders\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mdict\u001b[0m(raw_response.headers)}                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 688 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 689 \u001b[2m         \u001b[0mresponse = \u001b[96mself\u001b[0m.client.create(**payload)                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 690 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._create_chat_result(response, generation_info)                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 691 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 692 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_request_payload\u001b[0m(                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/_utils/\u001b[0m\u001b[1;33m_utils.py\u001b[0m:\u001b[94m275\u001b[0m in \u001b[92mwrapper\u001b[0m     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m272 \u001b[0m\u001b[2m               \u001b[0m\u001b[94melse\u001b[0m:                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m273 \u001b[0m\u001b[2m                  \u001b[0mmsg = \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mMissing required argument: \u001b[0m\u001b[33m{\u001b[0mquote(missing[\u001b[94m0\u001b[0m])\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m274 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(msg)                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m275 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m wrapper  \u001b[2m# type: ignore\u001b[0m                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m278 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/resources/chat/\u001b[0m\u001b[1;33mcompletions.py\u001b[0m:\u001b[94m829\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92mcreate\u001b[0m                                                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 826 \u001b[0m\u001b[2m      \u001b[0mtimeout: \u001b[96mfloat\u001b[0m | httpx.Timeout | \u001b[94mNone\u001b[0m | NotGiven = NOT_GIVEN,                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 827 \u001b[0m\u001b[2m   \u001b[0m) -> ChatCompletion | Stream[ChatCompletionChunk]:                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 828 \u001b[0m\u001b[2m      \u001b[0mvalidate_response_format(response_format)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 829 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._post(                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 830 \u001b[0m\u001b[2m         \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m/chat/completions\u001b[0m\u001b[33m\"\u001b[0m,                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 831 \u001b[0m\u001b[2m         \u001b[0mbody=maybe_transform(                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 832 \u001b[0m\u001b[2m            \u001b[0m{                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/\u001b[0m\u001b[1;33m_base_client.py\u001b[0m:\u001b[94m1278\u001b[0m in \u001b[92mpost\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1275 \u001b[0m\u001b[2m      \u001b[0mopts = FinalRequestOptions.construct(                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1276 \u001b[0m\u001b[2m         \u001b[0mmethod=\u001b[33m\"\u001b[0m\u001b[33mpost\u001b[0m\u001b[33m\"\u001b[0m, url=path, json_data=body, files=to_httpx_files(files), **opti  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1277 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1278 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m cast(ResponseT, \u001b[96mself\u001b[0m.request(cast_to, opts, stream=stream, stream_cls=str  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1279 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1280 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpatch\u001b[0m(                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1281 \u001b[0m\u001b[2m      \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/\u001b[0m\u001b[1;33m_base_client.py\u001b[0m:\u001b[94m955\u001b[0m in \u001b[92mrequest\u001b[0m      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 952 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 953 \u001b[0m\u001b[2m         \u001b[0mretries_taken = \u001b[94m0\u001b[0m                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 954 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 955 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._request(                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 956 \u001b[0m\u001b[2m         \u001b[0mcast_to=cast_to,                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 957 \u001b[0m\u001b[2m         \u001b[0moptions=options,                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 958 \u001b[0m\u001b[2m         \u001b[0mstream=stream,                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/Users/ogc2020/anaconda3/lib/python3.11/site-packages/openai/\u001b[0m\u001b[1;33m_base_client.py\u001b[0m:\u001b[94m1059\u001b[0m in \u001b[92m_request\u001b[0m    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1056 \u001b[0m\u001b[2m            \u001b[0merr.response.read()                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1057 \u001b[0m\u001b[2m         \u001b[0m                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1058 \u001b[0m\u001b[2m         \u001b[0mlog.debug(\u001b[33m\"\u001b[0m\u001b[33mRe-raising status error\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1059 \u001b[2m         \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mself\u001b[0m._make_status_error_from_response(err.response) \u001b[94mfrom\u001b[0m \u001b[94mNone\u001b[0m           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1060 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1061 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._process_response(                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1062 \u001b[0m\u001b[2m         \u001b[0mcast_to=cast_to,                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mAuthenticationError: \u001b[0mError code: \u001b[1;36m401\u001b[0m - \u001b[1m{\u001b[0m\u001b[32m'error'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'message'\u001b[0m: \u001b[32m'Incorrect API key provided: \u001b[0m\n",
       "\u001b[32msk-WsU5p***************************************qxp9. You can find your API key at \u001b[0m\n",
       "\u001b[32mhttps://platform.openai.com/account/api-keys.'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'invalid_request_error'\u001b[0m, \u001b[32m'param'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'code'\u001b[0m: \n",
       "\u001b[32m'invalid_api_key'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## test code\n",
    "from optimization_pipeline import OptimizationPipeline\n",
    "from utils.config import load_yaml, modify_input_for_ranker, validate_generation_config, override_config\n",
    "import argparse\n",
    "import os\n",
    "from estimator.estimator_llm import LLMEstimator\n",
    "\n",
    "# General Training Parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--generation_config_path', default='config/config_diff/config_generation.yml', type=str, help='Configuration file path')\n",
    "parser.add_argument('--ranker_config_path', default='config/config_diff/config_ranking.yml', type=str, help='Configuration file path')\n",
    "\n",
    "parser.add_argument('--task_description',\n",
    "                    default='',\n",
    "                    required=False, type=str, help='Describing the task')\n",
    "parser.add_argument('--prompt',\n",
    "                    default='',\n",
    "                    required=False, type=str, help='Prompt to use as initial.')\n",
    "parser.add_argument('--load_dump', default='', required=False, type=str, help='In case of loading from checkpoint')\n",
    "parser.add_argument('--output_dump', default='dump', required=False, type=str, help='Output to save checkpoints')\n",
    "parser.add_argument('--num_ranker_steps', default=10, type=int, help='Number of iterations')\n",
    "parser.add_argument('--num_generation_steps', default=20, type=int, help='Number of iterations')\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "\n",
    "ranker_config_params = override_config(opt.ranker_config_path)\n",
    "generation_config_params = override_config(opt.generation_config_path)\n",
    "validate_generation_config(ranker_config_params, generation_config_params)\n",
    "\n",
    "if opt.task_description == '':\n",
    "    task_description = input(\"Describe the task: \")\n",
    "else:\n",
    "    task_description = opt.task_description\n",
    "\n",
    "if opt.prompt == '':\n",
    "    initial_prompt = input(\"Initial prompt: \")\n",
    "else:\n",
    "    initial_prompt = opt.prompt\n",
    "\n",
    "ranker_pipeline = OptimizationPipeline(ranker_config_params, output_path=os.path.join(opt.output_dump, 'ranker'))\n",
    "if opt.load_dump != '':\n",
    "    ranker_pipeline.load_state(os.path.join(opt.load_dump, 'ranker'))\n",
    "    ranker_pipeline.predictor.init_chain(ranker_config_params.dataset.label_schema)\n",
    "\n",
    "if (ranker_pipeline.cur_prompt is None) or (ranker_pipeline.task_description is None):\n",
    "    ranker_mod_prompt, ranker_mod_task_desc = modify_input_for_ranker(\n",
    "        ranker_config_params, task_description, initial_prompt)\n",
    "    ranker_pipeline.cur_prompt = ranker_mod_prompt\n",
    "    ranker_pipeline.task_description = ranker_mod_task_desc\n",
    "\n",
    "# Adding debug statements before running the pipeline\n",
    "print(\"\\n=== Running Ranker Pipeline ===\")\n",
    "print(\"Current Prompt:\", ranker_pipeline.cur_prompt)\n",
    "print(\"Task Description:\", ranker_pipeline.task_description)\n",
    "\n",
    "best_prompt = ranker_pipeline.run_pipeline(opt.num_ranker_steps)\n",
    "\n",
    "# Adding debug statements after running the pipeline\n",
    "print(\"\\n=== Ranker Pipeline Completed ===\")\n",
    "print(\"Best Prompt from Ranker Pipeline:\", best_prompt)\n",
    "\n",
    "generation_config_params.eval.function_params = ranker_config_params.predictor.config\n",
    "generation_config_params.eval.function_params.instruction = best_prompt['prompt']\n",
    "generation_config_params.eval.function_params.label_schema = ranker_config_params.dataset.label_schema\n",
    "\n",
    "generation_pipeline = OptimizationPipeline(\n",
    "    generation_config_params, task_description, initial_prompt,\n",
    "    output_path=os.path.join(opt.output_dump, 'generator'))\n",
    "if opt.load_dump != '':\n",
    "    generation_pipeline.load_state(os.path.join(opt.load_dump, 'generator'))\n",
    "\n",
    "# Adding debug statements before running the generation pipeline\n",
    "print(\"\\n=== Running Generation Pipeline ===\")\n",
    "print(\"Instruction:\", generation_config_params.eval.function_params.instruction)\n",
    "print(\"Label Schema:\", generation_config_params.eval.function_params.label_schema)\n",
    "\n",
    "best_generation_prompt = generation_pipeline.run_pipeline(opt.num_generation_steps)\n",
    "\n",
    "print('\\033[92m' + 'Calibrated prompt score:', str(best_generation_prompt['score']) + '\\033[0m')\n",
    "print('\\033[92m' + 'Calibrated prompt:', best_generation_prompt['prompt'] + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original code\n",
    "from optimization_pipeline import OptimizationPipeline\n",
    "from utils.config import load_yaml, modify_input_for_ranker, validate_generation_config, override_config\n",
    "import argparse\n",
    "import os\n",
    "from estimator.estimator_llm import LLMEstimator\n",
    "# General Training Parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--generation_config_path', default='config/config_diff/config_generation.yml', type=str, help='Configuration file path')\n",
    "parser.add_argument('--ranker_config_path', default='config/config_diff/config_ranking.yml', type=str, help='Configuration file path')\n",
    "\n",
    "parser.add_argument('--task_description',\n",
    "                    default='',\n",
    "                    required=False, type=str, help='Describing the task')\n",
    "parser.add_argument('--prompt',\n",
    "                    default='',\n",
    "                    required=False, type=str, help='Prompt to use as initial.')\n",
    "parser.add_argument('--load_dump', default='', required=False, type=str, help='In case of loading from checkpoint')\n",
    "parser.add_argument('--output_dump', default='dump', required=False, type=str, help='Output to save checkpoints')\n",
    "parser.add_argument('--num_ranker_steps', default=5, type=int, help='Number of iterations')\n",
    "parser.add_argument('--num_generation_steps', default=20, type=int, help='Number of iterations')\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "\n",
    "\n",
    "ranker_config_params = override_config(opt.ranker_config_path)\n",
    "generation_config_params = override_config(opt.generation_config_path)\n",
    "validate_generation_config(ranker_config_params, generation_config_params)\n",
    "\n",
    "if opt.task_description == '':\n",
    "    task_description = input(\"Describe the task: \")\n",
    "else:\n",
    "    task_description = opt.task_description\n",
    "\n",
    "if opt.prompt == '':\n",
    "    initial_prompt = input(\"Initial prompt: \")\n",
    "else:\n",
    "    initial_prompt = opt.prompt\n",
    "\n",
    "ranker_pipeline = OptimizationPipeline(ranker_config_params, output_path=os.path.join(opt.output_dump, 'ranker'))\n",
    "if opt.load_dump != '':\n",
    "    ranker_pipeline.load_state(os.path.join(opt.load_dump, 'ranker'))\n",
    "    ranker_pipeline.predictor.init_chain(ranker_config_params.dataset.label_schema)\n",
    "\n",
    "if (ranker_pipeline.cur_prompt is None) or (ranker_pipeline.task_description is None):\n",
    "    ranker_mod_prompt, ranker_mod_task_desc = modify_input_for_ranker(ranker_config_params, task_description,\n",
    "                                                                      initial_prompt)\n",
    "    ranker_pipeline.cur_prompt = ranker_mod_prompt\n",
    "    ranker_pipeline.task_description = ranker_mod_task_desc\n",
    "\n",
    "best_prompt = ranker_pipeline.run_pipeline(opt.num_ranker_steps)\n",
    "generation_config_params.eval.function_params = ranker_config_params.predictor.config\n",
    "generation_config_params.eval.function_params.instruction = best_prompt['prompt']\n",
    "generation_config_params.eval.function_params.label_schema = ranker_config_params.dataset.label_schema\n",
    "\n",
    "\n",
    "generation_pipeline = OptimizationPipeline(generation_config_params, task_description, initial_prompt,\n",
    "                                           output_path=os.path.join(opt.output_dump, 'generator'))\n",
    "if opt.load_dump != '':\n",
    "    generation_pipeline.load_state(os.path.join(opt.load_dump, 'generator'))\n",
    "best_generation_prompt = generation_pipeline.run_pipeline(opt.num_generation_steps)\n",
    "print('\\033[92m' + 'Calibrated prompt score:', str(best_generation_prompt['score']) + '\\033[0m')\n",
    "print('\\033[92m' + 'Calibrated prompt:', best_generation_prompt['prompt'] + '\\033[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1 <span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Annotations in dataset:\"</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[<span style=\"color: #808000; text-decoration-color: #808000\">'annotation'</span>].unique())                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Label schema:\"</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_schema)                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'self'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1 \u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mAnnotations in dataset:\u001b[0m\u001b[33m\"\u001b[0m, \u001b[96mself\u001b[0m.dataset[\u001b[33m'\u001b[0m\u001b[33mannotation\u001b[0m\u001b[33m'\u001b[0m].unique())                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLabel schema:\u001b[0m\u001b[33m\"\u001b[0m, \u001b[96mself\u001b[0m.label_schema)                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'self'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Annotations in dataset:\", self.dataset['annotation'].unique())\n",
    "print(\"Label schema:\", self.label_schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
