annotator:
    method: 'llm'
    config:
        llm:
            type: 'OpenAI'
            name: 'gpt-4o-mini'
        instruction:
            'Assess whether the text contains a harmful topic. 
            Answer Yes if it does and No otherwise.'
        num_workers: 5
        prompt: 'prompts/predictor_completion/prediction.prompt'
        mini_batch_size: 1
        mode: 'annotation'

dataset:
    max_samples: 20
    label_schema:  ["1","2","3","4","5"]

predictor:
    method : 'llm'
    config:
        prompt: 'prompts/predictor_completion/prediction_generation.prompt'
        mini_batch_size: 1
        llm:
            type: 'OpenAI'
            name: 'gpt-4o-mini' #'gpt-3.5-turbo-1106'
        num_workers: 7

meta_prompts:
    folder: 'prompts/meta_prompts_generation'
    warmup: 1

eval:
    function_name: 'ranking'
    error_threshold: 4

